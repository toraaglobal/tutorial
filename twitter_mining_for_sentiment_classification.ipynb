{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_mining_for_sentiment_classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMx3Ze/DmVD2hgX9ZGH4YKJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toraaglobal/tutorial/blob/text_mining/twitter_mining_for_sentiment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDLw-HqxXrFU",
        "colab_type": "text"
      },
      "source": [
        "## Twitter Mining\n",
        "### Retriving live tweets from twitter using hash tag or keywords and save it in a file.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVtqorj0YXfl",
        "colab_type": "text"
      },
      "source": [
        "* Get twitter secrete and access key for authorization\n",
        "Go to twitter developer accout to request for access using this link https://developer.twitter.com/en/products/twitter-api\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jefaGU7ZhJF",
        "colab_type": "text"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9gY0rSFZ4yu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "36fbc946-46e3-4106-e35f-de28c6afab4e"
      },
      "source": [
        "%%bash\n",
        "pip install tweepy\n",
        "pip install wordcloud\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.7.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zq_2M2QapBE",
        "colab_type": "text"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxYwjYOqXHHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "import json\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "import sys\n",
        "import json\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import re\n",
        "from os import path\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from google.colab import drive\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV9nt0N_bRPc",
        "colab_type": "text"
      },
      "source": [
        "### Mount gdrive to access twitter authentication token and secret"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_tsbs6dYHtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0514d4c-867c-461f-ef9f-bcf22c317db2"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('./drive/My Drive/tool') # change directory"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cahf_MSjbpvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_twitter_auth():\n",
        "\tauth = []\n",
        "\tf = open(\"./auth.txt\", \"r\")\n",
        "\tfor line in f:\n",
        "\t\tauth.append(line.strip())\n",
        "\tf.close()\n",
        "\treturn auth\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shUtfPvIdXpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "authlist = get_twitter_auth()\n",
        "\n",
        "consumer_key = authlist[0]\n",
        "consumer_secret = authlist[1]\n",
        "access_token = authlist[2]\n",
        "access_secret = authlist[3]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcePL5DidvZy",
        "colab_type": "text"
      },
      "source": [
        "### Authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk9mbR7udRa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNKago6ke4LC",
        "colab_type": "text"
      },
      "source": [
        "### Custom class for tweets retrival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7TohIT1e-Sa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b58ce8b-1ef5-48cc-8a5c-16ca7c22aa07"
      },
      "source": [
        "\n",
        "class Listener(StreamListener):\n",
        "    print(\"In Listener...\") \n",
        "    tweet_number=0\n",
        "    def __init__(self, max_tweets, hfilename, rawfile):\n",
        "        self.max_tweets=max_tweets\n",
        "        print(self.max_tweets)\n",
        "\n",
        "    #on_data() is a function of StreamListener as is on_error and on_status    \n",
        "    def on_data(self, data):\n",
        "        self.tweet_number+=1 \n",
        "        print(\"In on_data\", self.tweet_number)\n",
        "        try:\n",
        "            print(\"In on_data in try\")\n",
        "            with open(hfilename, 'a') as f:\n",
        "                with open(rawfile, 'a') as g:\n",
        "                    tweet=json.loads(data)\n",
        "                    tweet_text=tweet[\"text\"]\n",
        "                    print(tweet_text,\"\\n\")\n",
        "                    f.write(tweet_text) # the text from the tweet\n",
        "                    json.dump(tweet, g)  #write the raw tweet\n",
        "        except BaseException:\n",
        "            print(\"NOPE\")\n",
        "            pass\n",
        "        if self.tweet_number>=self.max_tweets:\n",
        "            #sys.exit('Limit of '+str(self.max_tweets)+' tweets reached.')\n",
        "            print(\"Got \", str(self.max_tweets), \"tweets.\")\n",
        "            return False\n",
        "            \n",
        "    #method for on_error()\n",
        "    def on_error(self, status):\n",
        "        print(\"ERROR\")\n",
        "        if(status==420):\n",
        "            print(\"Error \", status, \"rate limited\")\n",
        "            return False\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In Listener...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV9CRoePgAlk",
        "colab_type": "text"
      },
      "source": [
        "### Tweets mining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-amycgwfxSY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41913b62-b9e9-48c0-b9e6-372eec8b6c52"
      },
      "source": [
        "hashname=input(\"Enter the hash name, such as #womensrights: \") \n",
        "numtweets=eval(input(\"How many tweets do you want to get?: \"))\n",
        "\n",
        "if(hashname[0]==\"#\"):\n",
        "    nohashname=hashname[1:] #remove the hash\n",
        "else:\n",
        "    nohashname=hashname\n",
        "    hashname=\"#\"+hashname\n",
        "\n",
        "#Create a file for any hash name    \n",
        "hfilename=\"file_\"+nohashname+\".txt\"\n",
        "# raw file\n",
        "rawfile=\"file_rawtweets_\"+nohashname+\".txt\"\n",
        "\n",
        "twitter_stream = Stream(auth, Listener(numtweets, hfilename, rawfile))\n",
        "\n",
        "#twitter_stream.filter(track=['#womensrights'])\n",
        "twitter_stream.filter(track=[hashname])\n",
        "print(\"Twitter files created....\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the hash name, such as #womensrights: covid19\n",
            "How many tweets do you want to get?: 50\n",
            "50\n",
            "In on_data 1\n",
            "In on_data in try\n",
            "RT @LauraSmithCrewe: Politician’s are going to now get distracted with Brexit wars whilst furlough ends, redundancies rise, covid rates soa… \n",
            "\n",
            "In on_data 2\n",
            "In on_data in try\n",
            "In sha Allah ❤❤❤ \n",
            "\n",
            "In on_data 3\n",
            "In on_data in try\n",
            "RT @ImranKhanPTI: کل سکول واپسی پر ہم لاکھوں بچوں کو خوش آمدید کہیں گے۔ یہ یقینی بنانا کہ ہر بچہ حصولِ علم کیلئےبحفاظت سکول جاسکے، ہماری تر… \n",
            "\n",
            "In on_data 4\n",
            "In on_data in try\n",
            "RT @Resist2Exist313: Large #antilockdownprotest took place in Bulgaria 🇧🇬 where protestors called on their government to resign accusing th… \n",
            "\n",
            "In on_data 5\n",
            "In on_data in try\n",
            "RT @RedLopezDiaz: Se confirma la reinfección por #COVID19 de una trabajadora del Sistema Estatal de Salud en #Puebla, informó el titular de… \n",
            "\n",
            "In on_data 6\n",
            "In on_data in try\n",
            "RT @marklouiegi55: CHED DOES NOT CARE ABOUT THE MENTAL AND PHYSICAL HEALTH OF STUDENTS PERIODT \n",
            "\n",
            "In on_data 7\n",
            "In on_data in try\n",
            "@sardesairajdeep Awwwwww. ...but not AS NICE a 'Photo Op\" these ones👇!!\n",
            "You and that poor innocent non-druggie… https://t.co/qUTjhRYEdx \n",
            "\n",
            "In on_data 8\n",
            "In on_data in try\n",
            "RT @marklouiegi55: CHED DOES NOT CARE ABOUT THE MENTAL AND PHYSICAL HEALTH OF STUDENTS PERIODT https://t.co/uuUSby2WlD \n",
            "\n",
            "In on_data 9\n",
            "In on_data in try\n",
            "RT @21WIRE: DANGEROUS: 33-year-old woman from #Perth #Australia becomes the first person fitted with state’s new electronic monitoring brac… \n",
            "\n",
            "In on_data 10\n",
            "In on_data in try\n",
            "RT @FatihAydinBey: Şu an ki verilere göre Yaptığım hesaplamalarda #Coronavirus kaynaklı ekstra olarak: 331426 kişinin daha ölümünü bekliyor… \n",
            "\n",
            "In on_data 11\n",
            "In on_data in try\n",
            "#BİRKUŞAKBİRYOL\n",
            "#OBOR \n",
            "\n",
            "#COVID19 un önlenmesi ve kontrolünün düzenli bir uygulama haline geldiği sırada, iki taraf… https://t.co/8bpf2o1ory \n",
            "\n",
            "In on_data 12\n",
            "In on_data in try\n",
            "RT @SusanSakmar: In addition to #hydrogen, lots of discussion on decarbonization and “green” #LNG at #GTVirtualSummit as industry continues… \n",
            "\n",
            "In on_data 13\n",
            "In on_data in try\n",
            "RT @YEDNetworkKe: #COVID19 attacks both young &amp; old; #ANYONE can get it. We can #AngamizaCorona by following all @MOH_Kenya #Covid19ke guid… \n",
            "\n",
            "In on_data 14\n",
            "In on_data in try\n",
            "RT @SelfHarmNotts: Important guidance on when to get children tested for CV19\n",
            "\n",
            "NB. Not just when they have cold symptoms ... \n",
            "\n",
            "In on_data 15\n",
            "In on_data in try\n",
            "RT @mkstalin: #NEET, #EIA, #COVID19 பற்றி பேரவையில் விவாதிக்க வேண்டும் என கோரியிருக்கிறோம்.\n",
            "\n",
            "அதிமுக அரசின் #NEET எதிர்ப்பு வெறும் நாடகம்! அ… \n",
            "\n",
            "In on_data 16\n",
            "In on_data in try\n",
            "RT @Nara_Hodge: Follow #COVID19 rules. No one is exempt. #RuleOfSix https://t.co/1Vss9AcZuR \n",
            "\n",
            "In on_data 17\n",
            "In on_data in try\n",
            "RT @beauty7313h: The Nigerian Voice-South Korea: Plasma Donation by Shincheonji Church Facilitates Development of the Vaccine for COVID-19… \n",
            "\n",
            "In on_data 18\n",
            "In on_data in try\n",
            "RT @ThDarkJedi_: En 2012 durant la crise étudiante, @Quebecor, avec l'aide de @RiMartineau, s'en ont pris aux jeunes! J'ai coupé le câble!… \n",
            "\n",
            "In on_data 19\n",
            "In on_data in try\n",
            "RT @azucenau: #ÚltimaHora Hoy por #Covid19 en México hay:\n",
            "\n",
            "-70 mil 821 muertes (217 más que ayer)\n",
            "\n",
            "-668 mil 381 casos confirmados (4 mil 40… \n",
            "\n",
            "In on_data 20\n",
            "In on_data in try\n",
            "RT @docrussjackson: In open defiance of state regulations &amp; his own administration’s #COVID19 guidelines, Trump hosted his first indoor ral… \n",
            "\n",
            "In on_data 21\n",
            "In on_data in try\n",
            "RT @itspcofficial: While India becomes the fastest growing nation in #COVID19 crisis, @narendramodi Ji chooses to be in denial of the grim… \n",
            "\n",
            "In on_data 22\n",
            "In on_data in try\n",
            "@MattHancock \n",
            "\n",
            "What the hell is the online booking system for getting a #COVID19 test in the #UK \n",
            "\n",
            "What a shambles… https://t.co/UEF0MD62sO \n",
            "\n",
            "In on_data 23\n",
            "In on_data in try\n",
            "RT @NewsDigestWeb: 【鳥取県で新たに2人感染確認】\n",
            "\n",
            "鳥取県+2（合計34人）\n",
            "※県発表\n",
            "\n",
            "きょうの国内感染者数は110人に\n",
            "（15:26時点）\n",
            "\n",
            "詳細は下記URLより：\n",
            "https://t.co/oEslL3cBpX\n",
            "\n",
            "#新型コロナウイルス #COVID19… \n",
            "\n",
            "In on_data 24\n",
            "In on_data in try\n",
            "RT @PTI_News: Congress leader Rahul Gandhi takes a dig at Prime Minister Narendra Modi over the rise in #COVID19 cases, says the government… \n",
            "\n",
            "In on_data 25\n",
            "In on_data in try\n",
            "RT @befree200: These images tell the story of 6 months of our government being at war with us. Pls share widely #COVID19 @pdebdon @garethic… \n",
            "\n",
            "In on_data 26\n",
            "In on_data in try\n",
            "The #Queensland suburbs where most hospitality workers have accessed their super amid #COVID19 shutdowns (via… https://t.co/sW7J2vqzib \n",
            "\n",
            "In on_data 27\n",
            "In on_data in try\n",
            "RT @NoFYLSOM: Here @NoFYLSOM, we are supremely grateful to our field monitors who are on the front lines of the #COVID19 response. We thank… \n",
            "\n",
            "In on_data 28\n",
            "In on_data in try\n",
            "Covid, her ülkede siyasi görüş/grup ve insanların arasındaki sınırları çatırdatıp ve bulanıklaştırıyor gibi.\n",
            "\n",
            "Virüs… https://t.co/CZehHFgRSf \n",
            "\n",
            "In on_data 29\n",
            "In on_data in try\n",
            "RT @MinistryDissent: This is sickening. \n",
            "\n",
            "In on_data 30\n",
            "In on_data in try\n",
            "\"world First Aid Day\"\n",
            "\n",
            "#meghmik #solutions #world #first #aid #day #job #Jobseekers #Safe #Consultant #recruiting… https://t.co/EH2N5Z0EK1 \n",
            "\n",
            "In on_data 31\n",
            "In on_data in try\n",
            "RT @accidental_sach: In the pic below the police is maintaining social distancing in view of the #COVID19 pandemic.\n",
            "\n",
            "The #DelhiPolice is pr… \n",
            "\n",
            "In on_data 32\n",
            "In on_data in try\n",
            "RT @Laissonslespre1: Merci à nos collègues d'Arabie Saoudite pour ce travail soulignant l'intérêt de l' #hydroxychloroquine en phase précoc… \n",
            "\n",
            "In on_data 33\n",
            "In on_data in try\n",
            "RT @ColefAndalucia: 😷💻 Este jueves, a partir de las 16:30, #webinar gratuito en streaming del @ConsejoCOLEF sobre ‘El uso de mascarilla en… \n",
            "\n",
            "In on_data 34\n",
            "In on_data in try\n",
            "RT @moayush: Homeopathic Drug Arsenicum Album 30C emerges as one of the most widely used prophylactic against #COVID19.\n",
            "\n",
            "Research centres u… \n",
            "\n",
            "In on_data 35\n",
            "In on_data in try\n",
            "RT @juliaioffe: Today is the beginning of week 5 of my having #COVID19. This time last week, I was nearly hospitalized. I am now on the up… \n",
            "\n",
            "In on_data 36\n",
            "In on_data in try\n",
            "RT @docprimum: #Covid_19 Ce qui est bien avec les gens compétents dans un domaine et pédagogues c'est que quand ils parlent de leur domaine… \n",
            "\n",
            "In on_data 37\n",
            "In on_data in try\n",
            "RT @vonDobrowolski: Weltweit gehen die Zahlen der #COVID19-Neuinfektionen wieder hoch. Israel geht in einen neuen Lockdown.\n",
            "Und Herbst und… \n",
            "\n",
            "In on_data 38\n",
            "In on_data in try\n",
            "RT @PTI_News: Congress leader Rahul Gandhi takes a dig at Prime Minister Narendra Modi over the rise in #COVID19 cases, says the government… \n",
            "\n",
            "In on_data 39\n",
            "In on_data in try\n",
            "RT @mkstalin: #NEET, #EIA, #COVID19 பற்றி பேரவையில் விவாதிக்க வேண்டும் என கோரியிருக்கிறோம்.\n",
            "\n",
            "அதிமுக அரசின் #NEET எதிர்ப்பு வெறும் நாடகம்! அ… \n",
            "\n",
            "In on_data 40\n",
            "In on_data in try\n",
            "RT @phl43: Lmao, look at the replies, it's full of people with \"MD\" in their username repeating that \"race is not biological\" like a mantra. \n",
            "\n",
            "In on_data 41\n",
            "In on_data in try\n",
            "#buktikemenanganjuraganqq #juraganqq #juragankiukiu #situspkv #pokeronline #bandarqonline\n",
            "#wfh #covid19… https://t.co/ZYOLsxN7Vq \n",
            "\n",
            "In on_data 42\n",
            "In on_data in try\n",
            "@ChrisMurphyCT @Alyssa_Milano Dear Ronna @GOPChairwoman,\n",
            "\n",
            "If @JoeBiden was POTUS, he would have AT LEAST told us to… https://t.co/bOG9cHSiTh \n",
            "\n",
            "In on_data 43\n",
            "In on_data in try\n",
            "RT @PTI_News: Congress leader Rahul Gandhi takes a dig at Prime Minister Narendra Modi over the rise in #COVID19 cases, says the government… \n",
            "\n",
            "In on_data 44\n",
            "In on_data in try\n",
            "RT @OSCE_RFoM: Journalism in times of #COVID19 &amp; growing lack of safety for media workers will be main points of discussion during the onli… \n",
            "\n",
            "In on_data 45\n",
            "In on_data in try\n",
            "RT @UnitedNationsJO: Misinformation is causing global harm, hampering our ability to make progress on many of the world’s most pressing iss… \n",
            "\n",
            "In on_data 46\n",
            "In on_data in try\n",
            "RT @MMMPAWAN: Class Attendance after rainy day.\n",
            "\n",
            "#LokSabha #ParliamentSession #Corona #COVID19 https://t.co/U8gDZlQEx1 \n",
            "\n",
            "In on_data 47\n",
            "In on_data in try\n",
            "RT @ImranKhanPTI: Tomorrow we will welcome millions of children back to school. It is our priority &amp; collective responsibility to ensure th… \n",
            "\n",
            "In on_data 48\n",
            "In on_data in try\n",
            "RT @rssurjewala: Alarming &amp; deeply distressing!\n",
            "\n",
            "PM must tell the Nation if the daily #COVID19 infection in India is actually 2,50,000.\n",
            "\n",
            "Wh… \n",
            "\n",
            "In on_data 49\n",
            "In on_data in try\n",
            "RT @ImranKhanPTI: کل سکول واپسی پر ہم لاکھوں بچوں کو خوش آمدید کہیں گے۔ یہ یقینی بنانا کہ ہر بچہ حصولِ علم کیلئےبحفاظت سکول جاسکے، ہماری تر… \n",
            "\n",
            "In on_data 50\n",
            "In on_data in try\n",
            "Dans cette période de crise sanitaire où la distanciation sociale est le maître mot, comment réaliser un entretien… https://t.co/2piisTQAlZ \n",
            "\n",
            "Got  50 tweets.\n",
            "Twitter files created....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8YXVljLhv_c",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKQ6TVYViYYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQMQMs1_gqLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linecount=0\n",
        "hashcount=0\n",
        "wordcount=0\n",
        "BagOfWords=[]\n",
        "BagOfHashes=[]\n",
        "BagOfLinks=[]\n",
        "\n",
        "tweetsfile=hfilename\n",
        "#tweetsfile = 'file_covid19.txt'\n",
        "\n",
        "filename=\"CleanText.csv\"\n",
        "NEWFILE=open(filename,\"w\")\n",
        "\n",
        "## In the first row, create a column called Label and a column Text...\n",
        "ToWrite=\"Label,Text\\n\"\n",
        "\n",
        "## Write this to new empty cs v file\n",
        "NEWFILE.write(ToWrite)\n",
        "\n",
        "## Close it up\n",
        "NEWFILE.close()\n",
        "NEWFILE=open(filename, \"a\")\n",
        "\n",
        "\n",
        "\n",
        "with open(tweetsfile, 'r') as file:\n",
        "    for line in file:\n",
        "        print(line,\"\\n\")\n",
        "        tweetSplitter = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
        "        WordList=tweetSplitter.tokenize(line)\n",
        "\n",
        "        regex1=re.compile('^#.+')\n",
        "        regex2=re.compile('[^\\W\\d]') #no numbers\n",
        "        regex3=re.compile('^http*')\n",
        "        regex4=re.compile('.+\\..+')\n",
        "        NewList =[]\n",
        "\n",
        "        for item in WordList:\n",
        "            if(len(item)>2):\n",
        "                if((re.match(regex1,item))):\n",
        "                    #print(item)\n",
        "                    newitem=item[1:] #remove the hash\n",
        "                    BagOfHashes.append(newitem)\n",
        "                    hashcount=hashcount+1\n",
        "                     # write each cleaned tweet on a line.    \n",
        "                    NewList.append(newitem)\n",
        "\n",
        "                elif(re.match(regex2,item)):\n",
        "                    if(re.match(regex3,item) or re.match(regex4,item)):\n",
        "                        BagOfLinks.append(item)\n",
        "                    else:\n",
        "                        BagOfWords.append(item)\n",
        "                        wordcount=wordcount+1\n",
        "                        # write each cleaned tweet on a line.\n",
        "                        NewList.append(item)\n",
        "                else:\n",
        "                    pass\n",
        "            else:\n",
        "                pass\n",
        "           \n",
        "        \n",
        "         # write each cleaned tweet on a line. \n",
        "        Text=\" \".join(NewList)\n",
        "        Text=\"\\t\"+\",\"+Text + \"\\n\"\n",
        "        NEWFILE.write(Text)\n",
        "        \n",
        "    \n",
        "NEWFILE.close()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzAuvAkNjON8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d68ed6db-b366-4b8a-fa48-f1adc36726fd"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(filename)\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\t</td>\n",
              "      <td>Politician are going now get distracted with B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\t</td>\n",
              "      <td>You and that poor innocent non-druggie CHED DO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\t</td>\n",
              "      <td>OBOR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\t</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\t</td>\n",
              "      <td>COVID19 önlenmesi kontrolünün düzenli bir uygu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label                                               Text\n",
              "0    \\t  Politician are going now get distracted with B...\n",
              "1    \\t  You and that poor innocent non-druggie CHED DO...\n",
              "2    \\t                                               OBOR\n",
              "3    \\t                                                NaN\n",
              "4    \\t  COVID19 önlenmesi kontrolünün düzenli bir uygu..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuBwyzUmjZA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}